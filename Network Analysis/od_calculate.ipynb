{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27965/27965 [01:45<00:00, 266.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD 表已保存到: result/od/od_table.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "name = '01-03'\n",
    "\n",
    "stay_points_path=f'result/stay_points/stay_points_{name}.csv'\n",
    "# polygons_path='result/clusters/cl_tmp.feather'\n",
    "polygons_path='result/clusters/cl_01-03.feather'\n",
    "output_path='result/od/od_table.csv'\n",
    "\n",
    "# 1. 读取停靠点数据\n",
    "df = pd.read_csv(stay_points_path)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], format='mixed', errors='coerce')\n",
    "df['timestamp_off'] = pd.to_datetime(df['timestamp_off'], format='mixed', errors='coerce')\n",
    "\n",
    "# 2. 读取港口多边形数据\n",
    "polygons_gdf = gpd.read_feather(polygons_path)\n",
    "\n",
    "# 3. 将停靠点转为 GeoDataFrame（需要指定坐标系，假设为 WGS84）\n",
    "gdf = gpd.GeoDataFrame(\n",
    "    df,\n",
    "    geometry=gpd.points_from_xy(df['longitude'], df['latitude']),\n",
    "    crs=\"EPSG:4326\"\n",
    ")\n",
    "\n",
    "# 4. 空间连接：将每个停靠点映射到其所在的多边形 label\n",
    "#   predicate='within' 表示点在多边形内部\n",
    "joined_gdf = gpd.sjoin(gdf, polygons_gdf, how='left', predicate='within')\n",
    "joined_gdf = joined_gdf[joined_gdf['label'].notna()]\n",
    "joined_gdf['label'] = joined_gdf['label'].astype(int)\n",
    "\n",
    "# 为避免冲突，将 polygons_gdf 中的 'label' 列重命名\n",
    "joined_gdf.rename(columns={'label': 'port_label'}, inplace=True)\n",
    "\n",
    "# 5. 对结果按 mmsi、timestamp 排序，便于构造连续 OD\n",
    "joined_gdf.sort_values(by=['mmsi', 'timestamp'], inplace=True)\n",
    "joined_gdf.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 6. 按 mmsi 分组，构造 OD\n",
    "od_records = []\n",
    "grouped = joined_gdf.groupby('mmsi', group_keys=True)\n",
    "\n",
    "# 使用 tqdm 显示分组进度\n",
    "for mmsi, group in tqdm(grouped, total=grouped.ngroups):\n",
    "    group = group.sort_values('timestamp').reset_index(drop=True)\n",
    "    \n",
    "    # 逐对取相邻记录\n",
    "    for i in range(len(group) - 1):\n",
    "        O = group.loc[i]\n",
    "        D = group.loc[i + 1]\n",
    "        \n",
    "        # 只记录 label 不同的 OD（即不同的港口多边形）\n",
    "        if O['port_label'] != D['port_label'] and O['timestamp_off'] < D['timestamp']:\n",
    "            od_records.append({\n",
    "                'mmsi': mmsi,\n",
    "                'O_label': O['port_label'],\n",
    "                'O_latitude': O['latitude'],\n",
    "                'O_longitude': O['longitude'],\n",
    "                'O_timestamp': O['timestamp_off'],       # 使用 timestamp_off\n",
    "                'D_label': D['port_label'],\n",
    "                'D_latitude': D['latitude'],\n",
    "                'D_longitude': D['longitude'],\n",
    "                'D_timestamp': D['timestamp']            # 使用下一条 timestamp\n",
    "            })\n",
    "\n",
    "# 7. 生成 OD 表并保存\n",
    "od_df = pd.DataFrame(od_records)\n",
    "od_df.to_csv(output_path, index=False)\n",
    "print(f\"OD 表已保存到: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OD 聚合结果已保存到: result/od/od_aggregated.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "date = pd.to_datetime('2022-02-24')\n",
    "day = 30\n",
    "\n",
    "# 1. 读取之前生成的 OD 表\n",
    "od_df = pd.read_csv('result/od/od_table.csv')\n",
    "\n",
    "od_df['O_timestamp'] = pd.to_datetime(od_df['O_timestamp'], errors='coerce')\n",
    "od_df['D_timestamp'] = pd.to_datetime(od_df['D_timestamp'], errors='coerce')\n",
    "\n",
    "if day > 0:\n",
    "    start_date = date\n",
    "    end_date = date + pd.Timedelta(days=day)\n",
    "else:\n",
    "    start_date = date + pd.Timedelta(days=day)\n",
    "    end_date = date\n",
    "od_df = (od_df[(od_df['O_timestamp'] >= start_date) & (od_df['D_timestamp'] < end_date)])\n",
    "\n",
    "# 2. 聚合 OD 表：按 O_label 和 D_label 分组，统计每组的船舶数\n",
    "agg_df = od_df.groupby(['O_label', 'D_label'], as_index=False).agg({'mmsi': 'count'})\n",
    "agg_df.rename(columns={'mmsi': 'count'}, inplace=True)\n",
    "\n",
    "\n",
    "# 3. 读取多边形数据，wp_tmp.feather，内含每个聚类的多边形和其他属性\n",
    "polygons_gdf = gpd.read_feather(f'result/clusters/cl_{name}.feather')\n",
    "\n",
    "# 4. 计算每个多边形的质心，并提取质心的经纬度\n",
    "polygons_gdf['centroid'] = polygons_gdf.geometry.centroid\n",
    "polygons_gdf['centroid_lat'] = polygons_gdf.centroid.y\n",
    "polygons_gdf['centroid_lon'] = polygons_gdf.centroid.x\n",
    "\n",
    "# 5. 创建映射：以 label 为键，质心坐标为值\n",
    "label_to_centroid = polygons_gdf.set_index('label')[['centroid_lat', 'centroid_lon']]\n",
    "\n",
    "# 6. 将质心信息合并到聚合的 OD 表中\n",
    "# 合并 O_label 的质心\n",
    "agg_df = agg_df.merge(label_to_centroid, left_on='O_label', right_index=True, how='left')\n",
    "agg_df.rename(columns={'centroid_lat': 'O_latitude', 'centroid_lon': 'O_longitude'}, inplace=True)\n",
    "\n",
    "# 合并 D_label 的质心，使用不同的后缀\n",
    "agg_df = agg_df.merge(label_to_centroid, left_on='D_label', right_index=True, how='left', suffixes=('', '_D'))\n",
    "agg_df.rename(columns={'centroid_lat': 'D_latitude', 'centroid_lon': 'D_longitude'}, inplace=True)\n",
    "\n",
    "# 7. 调整输出列顺序（不需要时间字段）\n",
    "agg_df = agg_df[['O_label', 'O_latitude', 'O_longitude', 'D_label', 'D_latitude', 'D_longitude', 'count']]\n",
    "\n",
    "# 8. 保存结果到 CSV 文件\n",
    "output_csv = 'result/od/od_aggregated.csv'\n",
    "agg_df.to_csv(output_csv, index=False)\n",
    "print(f\"OD 聚合结果已保存到: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing days: 100%|██████████| 59/59 [00:21<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "动态图已保存到: result/od/dynamic_graph.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设定日期和时间范围\n",
    "date = pd.to_datetime('2022-02-24')\n",
    "day_range = range(-30, 30)\n",
    "\n",
    "# 1. 读取之前生成的 OD 表\n",
    "od_df = pd.read_csv('result/od/od_table.csv')\n",
    "\n",
    "# 转换时间戳为 datetime 类型\n",
    "od_df['O_timestamp'] = pd.to_datetime(od_df['O_timestamp'], errors='coerce')\n",
    "od_df['D_timestamp'] = pd.to_datetime(od_df['D_timestamp'], errors='coerce')\n",
    "\n",
    "# 2. 初始化一个空的列表用于存储转换后的动态图数据\n",
    "graph_records = []\n",
    "\n",
    "# 3. 遍历 day_range 来处理每一天\n",
    "for day in tqdm(day_range, desc=\"Processing days\"):\n",
    "    # 计算当前时间（以0点为准）\n",
    "    current_time = date + pd.Timedelta(days=day)\n",
    "    \n",
    "    # 4. 按条件筛选：O_timestamp <= current_time <= D_timestamp\n",
    "    valid_od_df = od_df[(od_df['O_timestamp'] <= current_time) & (od_df['D_timestamp'] >= current_time)]\n",
    "    \n",
    "    # 5. 聚合每个 (source, target, time) 的记录，计算 weight\n",
    "    for _, group in valid_od_df.groupby(['O_label', 'D_label']):\n",
    "        # 每个 (source, target) 组合对应的时间和权重\n",
    "        group_time = current_time\n",
    "        weight = len(group)\n",
    "        \n",
    "        # 6. 记录到图数据中\n",
    "        for _, row in group.iterrows():\n",
    "            graph_records.append({\n",
    "                'source': row['O_label'],\n",
    "                'target': row['D_label'],\n",
    "                'weight': weight,\n",
    "                'time': group_time\n",
    "            })\n",
    "\n",
    "# 7. 将所有记录转换为 DataFrame\n",
    "graph_df = pd.DataFrame(graph_records)\n",
    "\n",
    "# 8. 将结果保存到 CSV 文件\n",
    "graph_df.to_csv('result/od/dynamic_graph.csv', index=False)\n",
    "print(\"动态图已保存到: result/od/dynamic_graph.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
